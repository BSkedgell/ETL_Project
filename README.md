# ETL_Project

Readme.md
Contributors: Brian, Judy and Anna
Your group decides that they want to deliver a normalized database of income in Los Angeles.
You figure that this should use 2 database tables:
-	“median_income_table “
-	“neighborhood”
To begin with use Python and SqlAlchemy.
Scrape the data from the following page:
https://usc.data.socrata.com/Los-Angeles/Income-LA-/kygc-fzgm
Extract, clean, parse and transform data. 



 

After cleaning and parsing the data login to the database and truncate the appropriate staging table where the data will be loaded (delete all records in the table) and then load the data .


Schema sql contains MySql database schema
extractor.py (in progress0
transformer.py (in progress)
loader.py(in progress)

Then we loaded the data into the target data store, commonly called a data warehouse


